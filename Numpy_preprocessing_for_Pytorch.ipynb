{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPICOmFskUwZvRfjdFxFYbJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/ImageProcessing/blob/master/Numpy_preprocessing_for_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Numpy image processing for Pytorch**\n",
        "\n"
      ],
      "metadata": {
        "id": "rMjtLDqQahey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import IPython\n",
        "import shutil\n",
        "import glob\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#GDriveをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPoA9fqDbESK",
        "outputId": "94f90e90-c2e8-46c4-84e5-7c7775c7b8f0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.12.1+cu113 CPU\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_newPatient_250px\"\n",
        "\n",
        "img_list = glob.glob(f\"{image_folder}/*\")\n",
        "img = img_list[0]\n",
        "print(img)\n",
        "\n",
        "#showimage\n",
        "# img = \"/content/drive/MyDrive/Deep_learning/Face_Images/test_dog.jpg\"\n",
        "img_np = np.array(Image.open(img)).astype(np.float32)\n",
        "print(img_np)\n",
        "plt.imshow((img_np).astype(np.uint8))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g_6_yFhobGhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ImageNetでnormalizeする（ImageとNumpyで255倍異なるので補正）\n",
        "def zscore(x, axis=None):\n",
        "    # xmean = x.mean(axis=axis, keepdims=True)\n",
        "    xmean = [n*255 for n in [0.485, 0.456, 0.406]]\n",
        "    # xstd = np.std(x, axis=axis, keepdims=True)\n",
        "    xstd = [n*255 for n in [0.229, 0.224, 0.225]]\n",
        "    zscore = (x-xmean)/xstd\n",
        "    return zscore\n",
        "\n",
        "PIL_img = Image.open(img)\n",
        "PIL_img = PIL_img.resize((224,224), resample=0)\n",
        "\n",
        "#convert PIL to numpy\n",
        "img_np = np.array(PIL_img).astype(np.float32)\n",
        "img_np = zscore(img_np)\n",
        "\n",
        "print(img_np)\n",
        "\n",
        "plt.imshow(img_np)\n",
        "print(img_np)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bBki6N5nkrgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.transformsと同じ値になることを確認\n",
        "from torchvision import models, transforms\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "PIL_img = Image.open(img)\n",
        "img_tensor = preprocess(PIL_img)\n",
        "img_np = img_tensor.to(\"cpu\").detach().numpy().transpose(1, 2, 0).copy()\n",
        "print(img_np)"
      ],
      "metadata": {
        "id": "ulyJBywpcSWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Preprocess multiple images**"
      ],
      "metadata": {
        "id": "WNAQ_Bu1H3tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orig_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_newPatient_250px/aaa.jpg\"\n",
        "os.path.basename(orig_path)\n"
      ],
      "metadata": {
        "id": "ZEXv0OrUKnVx",
        "outputId": "28dd6090-d329-49a7-8aac-0066fa2218d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'aaa.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models, transforms\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "orig_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_newPatient_250px\"\n",
        "dst_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_newPatient_224px_normalized\"\n",
        "\n",
        "def preprocess(img):\n",
        "    PIL_img = Image.open(img)\n",
        "    img_tensor = preprocess(PIL_img)\n",
        "    img_np = img_tensor.to(\"cpu\").detach().numpy().transpose(1, 2, 0).copy()\n",
        "    PIL_image = Image.fromarray(img_np)\n",
        "    print(PIL_image)\n",
        "\n",
        "if os.path.exists(dst_folder):\n",
        "    shutil.rmtree(dst_folder)\n",
        "os.makedirs(dst_folder) \n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "for path in glob.glob(f\"{orig_folder}/*\"):\n",
        "    img = Image.open(path)\n",
        "    pil_img = preprocess(img)\n",
        "    print(pil_img)\n",
        "    #pil_img.save(f\"{os.path.basename(path)}\")\n",
        "    print(f\"{os.path.basename(path)} saved!\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8Rr1qK6Pok-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tN9XbLU6LS9F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}